{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnmZ4GCb9K8VIU9+jiRvUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alka709/DeepLearning_Projects/blob/main/Simple_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "63C52LeDcLl9"
      },
      "outputs": [],
      "source": [
        "text=\"\"\"Kerala is a beautiful state on the southwest coast of India, famous for its incredible natural beauty and unique culture. It is often called \"God's Own Country.\"\n",
        "\n",
        "The state is best known for its backwaters, which are calm rivers and canals connected to the sea. Cruising through these peaceful waters on a traditional houseboat is a major attraction, especially in places like Alleppey. You'll also find cool, green hill stations like Munnar, covered in rolling tea plantations.\n",
        "\n",
        "Kerala has a high standard of living, with the highest literacy rate in India. It is the home of Ayurveda, an ancient Indian way of natural healing and medicine. The culture is rich with amazing art forms, including the classical dance-drama Kathakali, where performers wear heavy makeup and costumes to tell stories.\n",
        "\n",
        "If you visit, you can enjoy the tranquil beaches, spice gardens, and colorful festivals like Onam. It's a truly unique and relaxing destination.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "QmX9JzLbclBN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "fnTLsNbmc6DU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([text])"
      ],
      "metadata": {
        "id": "F2bG-GpudE6Z"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJkrTWuodTWu",
        "outputId": "e678a573-e550-409e-8f39-07fa5fd7b95b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'is': 2,\n",
              " 'and': 3,\n",
              " 'a': 4,\n",
              " 'of': 5,\n",
              " 'in': 6,\n",
              " 'like': 7,\n",
              " 'kerala': 8,\n",
              " 'state': 9,\n",
              " 'on': 10,\n",
              " 'india': 11,\n",
              " 'for': 12,\n",
              " 'its': 13,\n",
              " 'natural': 14,\n",
              " 'unique': 15,\n",
              " 'culture': 16,\n",
              " 'it': 17,\n",
              " 'to': 18,\n",
              " 'with': 19,\n",
              " 'you': 20,\n",
              " 'beautiful': 21,\n",
              " 'southwest': 22,\n",
              " 'coast': 23,\n",
              " 'famous': 24,\n",
              " 'incredible': 25,\n",
              " 'beauty': 26,\n",
              " 'often': 27,\n",
              " 'called': 28,\n",
              " \"god's\": 29,\n",
              " 'own': 30,\n",
              " 'country': 31,\n",
              " 'best': 32,\n",
              " 'known': 33,\n",
              " 'backwaters': 34,\n",
              " 'which': 35,\n",
              " 'are': 36,\n",
              " 'calm': 37,\n",
              " 'rivers': 38,\n",
              " 'canals': 39,\n",
              " 'connected': 40,\n",
              " 'sea': 41,\n",
              " 'cruising': 42,\n",
              " 'through': 43,\n",
              " 'these': 44,\n",
              " 'peaceful': 45,\n",
              " 'waters': 46,\n",
              " 'traditional': 47,\n",
              " 'houseboat': 48,\n",
              " 'major': 49,\n",
              " 'attraction': 50,\n",
              " 'especially': 51,\n",
              " 'places': 52,\n",
              " 'alleppey': 53,\n",
              " \"you'll\": 54,\n",
              " 'also': 55,\n",
              " 'find': 56,\n",
              " 'cool': 57,\n",
              " 'green': 58,\n",
              " 'hill': 59,\n",
              " 'stations': 60,\n",
              " 'munnar': 61,\n",
              " 'covered': 62,\n",
              " 'rolling': 63,\n",
              " 'tea': 64,\n",
              " 'plantations': 65,\n",
              " 'has': 66,\n",
              " 'high': 67,\n",
              " 'standard': 68,\n",
              " 'living': 69,\n",
              " 'highest': 70,\n",
              " 'literacy': 71,\n",
              " 'rate': 72,\n",
              " 'home': 73,\n",
              " 'ayurveda': 74,\n",
              " 'an': 75,\n",
              " 'ancient': 76,\n",
              " 'indian': 77,\n",
              " 'way': 78,\n",
              " 'healing': 79,\n",
              " 'medicine': 80,\n",
              " 'rich': 81,\n",
              " 'amazing': 82,\n",
              " 'art': 83,\n",
              " 'forms': 84,\n",
              " 'including': 85,\n",
              " 'classical': 86,\n",
              " 'dance': 87,\n",
              " 'drama': 88,\n",
              " 'kathakali': 89,\n",
              " 'where': 90,\n",
              " 'performers': 91,\n",
              " 'wear': 92,\n",
              " 'heavy': 93,\n",
              " 'makeup': 94,\n",
              " 'costumes': 95,\n",
              " 'tell': 96,\n",
              " 'stories': 97,\n",
              " 'if': 98,\n",
              " 'visit': 99,\n",
              " 'can': 100,\n",
              " 'enjoy': 101,\n",
              " 'tranquil': 102,\n",
              " 'beaches': 103,\n",
              " 'spice': 104,\n",
              " 'gardens': 105,\n",
              " 'colorful': 106,\n",
              " 'festivals': 107,\n",
              " 'onam': 108,\n",
              " \"it's\": 109,\n",
              " 'truly': 110,\n",
              " 'relaxing': 111,\n",
              " 'destination': 112}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-wFtjV0n4Kg",
        "outputId": "00ebce02-8902-4f06-9497-c789de936336"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "112"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "for sentence in text.split('\\n'):\n",
        "  tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1,len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])\n"
      ],
      "metadata": {
        "id": "7D5RYTTnddwg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_sequences"
      ],
      "metadata": {
        "id": "0mJc_mj-eMPV"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "max_len=max([len(x) for x in input_sequences])\n",
        "print(max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKDyP-mdf3Zy",
        "outputId": "3b637329-5a1f-498c-86f6-ce64e149b9d4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_seuences=pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
      ],
      "metadata": {
        "id": "x9v3kMS1g31M"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_seuences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u9Jx4hthMka",
        "outputId": "7c32c4d0-6e10-4ef4-9f3e-c0803309c589"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,   8,   2],\n",
              "       [  0,   0,   0, ...,   8,   2,   4],\n",
              "       [  0,   0,   0, ...,   2,   4,  21],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 110,  15,   3],\n",
              "       [  0,   0,   0, ...,  15,   3, 111],\n",
              "       [  0,   0,   0, ...,   3, 111, 112]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=padded_input_seuences[:,:-1]\n",
        "y=padded_input_seuences[:,-1]"
      ],
      "metadata": {
        "id": "y3k-ic-mhpUC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBOsk_NUoidM",
        "outputId": "5c5b5cbd-4584-4620-befc-b40169ccf587"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9I6gSEooipq",
        "outputId": "5fef06b0-a992-4152-d681-092e53743902"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149,)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y=to_categorical(y,num_classes=113)  #we take len(tokenizer.word_index)+1 =112+1=113 bcz One Hot encoding starts wuth 0 and tokenizer started with 1"
      ],
      "metadata": {
        "id": "td5TkaY7hvfK"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mxfNMhkoL7h",
        "outputId": "0e8db94a-12c7-42f2-9f6f-2a9868303b18"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(149, 113)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,Dense,LSTM"
      ],
      "metadata": {
        "id": "XL-d5yLBoni5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(113,100,input_length=52))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(113,activation='softmax'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw9C-FxVpQOh",
        "outputId": "629eb54f-e0c1-4170-fc0c-2419cf694920"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HiKUnFFYqLP_"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(None, 52))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "UcG3AjeGrBXL",
        "outputId": "d839fda2-40de-4708-e643-11cb897a4dec"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m11,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m113\u001b[0m)            │        \u001b[38;5;34m17,063\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">17,063</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m178,963\u001b[0m (699.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,963</span> (699.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m178,963\u001b[0m (699.07 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">178,963</span> (699.07 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sample=\"kerala\"\n",
        "token_text=tokenizer.texts_to_sequences([sample])[0]\n",
        "padded_token_text=pad_sequences([token_text],maxlen=52,padding='pre')\n",
        "pos=np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "for word,index in tokenizer.word_index.items():\n",
        "    if index==pos:\n",
        "        print(word)\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsjlpYxLrGEH",
        "outputId": "1798ecfa-118d-47b4-c3e1-b3e65fcfa564"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 234ms/step\n",
            "onam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "sample=\"kerala\"\n",
        "for i in range(5):\n",
        "  token_text=tokenizer.texts_to_sequences([sample])[0]\n",
        "  padded_token_text=pad_sequences([token_text],maxlen=52,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "      if index==pos:\n",
        "          sample=sample+\" \"+word\n",
        "          print(sample)\n",
        "          time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S42OUrO9x3Cp",
        "outputId": "024e5d15-87a5-4b47-b9c4-7f9559421045"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "kerala onam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "kerala onam onam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "kerala onam onam major\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "kerala onam onam major known\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "kerala onam onam major known major\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "sample=\"kerala has\"\n",
        "for i in range(5):\n",
        "  token_text=tokenizer.texts_to_sequences([sample])[0]\n",
        "  padded_token_text=pad_sequences([token_text],maxlen=52,padding='pre')\n",
        "  pos=np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word,index in tokenizer.word_index.items():\n",
        "      if index==pos:\n",
        "          sample=sample+\" \"+word\n",
        "          print(sample)\n",
        "          time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf6m5qjby2Wl",
        "outputId": "ace7f9c2-638d-440c-e0ae-56db282b1a7f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "kerala has onam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "kerala has onam onam\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "kerala has onam onam major\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "kerala has onam onam major kerala\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "kerala has onam onam major kerala kerala\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_1NMxjnC0jQL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}